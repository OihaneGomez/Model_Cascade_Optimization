{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '1'\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import random as rn\n",
    "rn.seed(1)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import kurtosis \n",
    "from scipy.stats import skew\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#from yellowbrick.features.importances import FeatureImportances\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "from sklearn.pipeline import Pipeline  \n",
    "import matplotlib.style as style \n",
    "from sklearn.pipeline import Pipeline       \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import gc\n",
    "from numpy import sqrt\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from scipy import interp\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Variables\n",
    "\n",
    "- root: Select the folder name of your dataset\n",
    "- initial component list, number_initial_components: Create the list containing the available signals and the number of them you would like to initially consider\n",
    "- best_features_number: Select the máximun number of features to process (in this case 486 for the 9 initial signals)\n",
    "- Dnumber_of_segments: Determine the number of subwinsdows in which every data example will be segmented\n",
    "- n_splits: the number of folds in the cross validation \n",
    "- n_times: constant to determine how many times results will be obtained and averaged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset folder relative route\n",
    "root = './OHM_Dataset/' \n",
    "\n",
    "\"\"\"\n",
    " Available signals: acc x,y,z \n",
    "                    gyro x,y,z , \n",
    "                    pitch roll and yaw\n",
    "\"\"\"\n",
    "\n",
    "initial_componet_list=[\"x\", \"y\", \"z\", \"gyrox\", \"gyroy\", \"gyroz\", \"pitch\",\"roll\",\"yaw\"]\n",
    "\n",
    "#In case you want to reduce the number of signals \n",
    "number_initial_components = 9\n",
    "initial_data_reduced_names = initial_componet_list[0:number_initial_components ]\n",
    "\n",
    "#Best feature number to process \n",
    "#(Max 486 for 9 Signals)\n",
    "best_features_number=486\n",
    "\n",
    "#Number of subwindos in which every window is divided\n",
    "number_of_segments=5\n",
    "\n",
    "#Number in X-fold Cross Validation\n",
    "n_splits=5\n",
    "\n",
    "#Repeat the cross validation n_times and average final results\n",
    "n_times = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Cascade Configuration\n",
    "\n",
    "- Log_loss_T, log_loss_T_sel: Set the confidence threshold according to its log loss value for model 1-2 and model 2-3 of the cascade\n",
    "\n",
    "- n_features_mN: Select the number of features used in every model N\n",
    "\n",
    "- segments_mN: Determine wheter the models are created using the segmented data or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Threshold 1\n",
    "log_loss_T=0.15\n",
    "#Threshold 2\n",
    "log_loss_T_sel=0.4\n",
    "\n",
    "\n",
    "#Determine wheter the classification will rely on the segmented instances or not\n",
    "#segments True= segmened \n",
    "#segments False = NO segmented\n",
    "\n",
    "\n",
    "#----------------model 1\n",
    "n_features_m1=10 #number of selected features for model 1\n",
    "segments_m1=True\n",
    "\n",
    "#----------------model 2\n",
    "n_features_m2=50 #number of selected features for model 2\n",
    "segments_m2=True\n",
    "\n",
    "\n",
    "\n",
    "#----------------model 3 (Final)\n",
    "n_features_m3=486 #(all features)\n",
    "segments_m3=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Other', 'Drink_glass', 'Drink_bottle']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Create activities dictionary \n",
    "wrist_class = {'Other':0, \n",
    "              'Drink_glass':1, \n",
    "               'Drink_bottle':2, \n",
    "             }\n",
    "\n",
    "n=0\n",
    "best_features_num=[best_features_number]\n",
    "\n",
    "#Activity label list\n",
    "wrist_labels = sorted(wrist_class, key=lambda x: x[1], reverse=True)\n",
    "labels=wrist_labels\n",
    "number_classes=len(wrist_labels)\n",
    "print(wrist_labels)\n",
    "\n",
    "\n",
    "#Funtion to import all the txt for every class, calculate its features and append it in a Matrix\n",
    "def gather(class_dict,split_index,segments):\n",
    "    df = []\n",
    "    for c in class_dict.keys():\n",
    "        f = glob.glob(root + c + '/*') #Get all files \n",
    "        d = pd.DataFrame(reformat(f, cls=c,split_index=split_index, segments=segments)) #Pandas dataframe for reformat funtion features\n",
    "        df.append(d)\n",
    "    return pd.concat(df)\n",
    "\n",
    "\n",
    "#Median Filter axiliar function \n",
    "def strided_app(a, L, S ):  # Window len = L, Stride len/stepsize = S\n",
    "    nrows = ((a.size-L)//S)+1\n",
    "    n = a.strides[0]\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=(nrows,L), strides=(S*n,n)) \n",
    "\n",
    "\n",
    "\n",
    "#Obtain Data values for every secuence/instance\n",
    "def reformat(files, cls,  split_index, segments):\n",
    "    big_list= []\n",
    "    for f in files:\n",
    "        #Read every txt file (Number of row value_x, Value_Y, Value_Z)\n",
    "        data = pd.read_csv(f, sep=',', header=None, names=['x', 'y', 'z', 'gyrox' , 'gyroy', 'gyroz', 'pitch', 'roll', 'yaw']) \n",
    "\n",
    "        \n",
    "        df_x = data.iloc[:,0:1]\n",
    "        df_y = data.iloc[:,1:2]\n",
    "        df_z = data.iloc[:,2:3]\n",
    "    \n",
    "        df_gyrox = data.iloc[:,3:4]\n",
    "        df_gyroy = data.iloc[:,4:5]\n",
    "        df_gyroz = data.iloc[:,5:6]\n",
    "        \n",
    "        df_pitch = data.iloc[:,6:7]\n",
    "        df_roll = data.iloc[:,7:8]\n",
    "        df_yaw = data.iloc[:,8:9]\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Median filtering\n",
    "        x = np.median(strided_app(df_x.values.flatten(), 3,1),axis=1)\n",
    "        y = np.median(strided_app(df_y.values.flatten(), 3,1),axis=1)\n",
    "        z = np.median(strided_app(df_z.values.flatten(), 3,1),axis=1)\n",
    "        \n",
    "        gyrox = np.median(strided_app(df_gyrox.values.flatten(), 3,1),axis=1)\n",
    "        gyroy = np.median(strided_app(df_gyroy.values.flatten(), 3,1),axis=1)\n",
    "        gyroz = np.median(strided_app(df_gyroz.values.flatten(), 3,1),axis=1)\n",
    "        \n",
    "        pitch = np.median(strided_app(df_pitch.values.flatten(), 3,1),axis=1)\n",
    "        roll = np.median(strided_app(df_roll.values.flatten(), 3,1),axis=1)\n",
    "        yaw = np.median(strided_app(df_yaw.values.flatten(), 3,1),axis=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        data_all=pd.concat([df_x.reset_index(drop=True), df_y.reset_index(drop=True), df_z.reset_index(drop=True),\n",
    "                           df_gyrox.reset_index(drop=True), df_gyroy.reset_index(drop=True), df_gyroz.reset_index(drop=True) ,\n",
    "                           df_pitch.reset_index(drop=True), df_roll.reset_index(drop=True), df_yaw.reset_index(drop=True),\n",
    "                           ],\n",
    "                           \n",
    "                           axis=1)\n",
    "        \n",
    "        \n",
    "        data_reduced = data_all.iloc[:,0:number_initial_components ]\n",
    "        \n",
    "        \n",
    "        #Split selected component of every secuence in X segments\n",
    "        split_index=split_index #Number of segments\n",
    "        data_split=np.array_split(data_reduced, split_index)\n",
    "        \n",
    "        appended_features=[]\n",
    "        \n",
    "        #Features calculation\n",
    "        features_whole = pd.concat([data_reduced.mean(axis=0).rename(index=lambda x: 'mean' + '_' + x), \n",
    "                              #Dataframe \n",
    "                              data_reduced.std(axis=0).rename(index=lambda x: 'std' + '_' + x),\n",
    "                              data_reduced.median(axis=0).rename(index=lambda x: 'median' + '_' + x), \n",
    "                              data_reduced.mad(axis=0).rename(index=lambda x: 'mad' + '_' + x), \n",
    "                              data_reduced.max(axis=0).rename(index=lambda x: 'max' + '_' + x),\n",
    "                              data_reduced.kurtosis(axis=0).rename(index=lambda x: 'kur' + '_' + x),  \n",
    "                              data_reduced.skew(axis=0).rename(index=lambda x: 'skw' + '_' + x), \n",
    "                              data_reduced.var(axis=0).rename(index=lambda x: 'var' + '_' + x),   \n",
    "                              data_reduced.min(axis=0).rename(index=lambda x: 'min' + '_' + x)])\n",
    "        \n",
    "        for i in range(0, split_index):\n",
    "            #Features for every segment of data\n",
    "            features= pd.concat([data_split[i].mean(axis=0).rename(index=lambda x: 'mean' + '_' + x + '_' + str(i)), \n",
    "                              data_split[i].std(axis=0).rename(index=lambda x: 'std' + '_' + x + '_' + str(i)),\n",
    "                              data_split[i].median(axis=0).rename(index=lambda x: 'median' + '_' + x + '_' + str(i)), \n",
    "                              data_split[i].mad(axis=0).rename(index=lambda x: 'mad' + '_' + x + '_' + str(i)), \n",
    "                              data_split[i].max(axis=0).rename(index=lambda x: 'max' + '_' + x + '_' + str(i)),\n",
    "                              data_split[i].kurtosis(axis=0).rename(index=lambda x: 'kur' + '_' + x + '_' + str(i)),  \n",
    "                              data_split[i].skew(axis=0).rename(index=lambda x: 'skw' + '_' + x + '_' + str(i)),\n",
    "                              #data_split[i].sum(axis=0).rename(index=lambda x: 'sum' + '_' + x + '_' + str(i)), \n",
    "                              data_split[i].var(axis=0).rename(index=lambda x: 'var' + '_' + x + '_' + str(i)),\n",
    "                              data_split[i].min(axis=0).rename(index=lambda x: 'min' + '_' + x + '_' + str(i))])\n",
    "            appended_features.append(features)\n",
    "        \n",
    "        #Concat all obtained features\n",
    "        if segments is False:\n",
    "             appended_features_all = pd.concat([features_whole])\n",
    "             \n",
    "        else:\n",
    "            #Concat all obtained features\n",
    "             \n",
    "            appended_features_all = pd.concat([features_whole])\n",
    "            for i in range (0, split_index):\n",
    "                appended_features_all = pd.concat([appended_features_all, appended_features[i]])\n",
    "                    \n",
    "        \n",
    "\n",
    "        \n",
    "        #Access to dictionary class number and add it as a feature\n",
    "        appended_features_all['Y'] = wrist_class[cls]\n",
    "        big_list.append(appended_features_all)\n",
    "\n",
    "    #Return table containing all rows for every class and feature colums \n",
    "    #(mean*3, sd*3, Max*3, Min*3, Y). Number of the row is manteined. (0~101)\n",
    "    return big_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data processing with subwindows\n",
    "\n",
    "when segments = True\n",
    "\n",
    "Each sequence of data is segmented in 5 subwindows and features all calculated for each of the 5 segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 486\n",
      "Feature names  ['mean_x', 'mean_y', 'mean_z', 'mean_gyrox', 'mean_gyroy', 'mean_gyroz', 'mean_pitch', 'mean_roll', 'mean_yaw', 'std_x', 'std_y', 'std_z', 'std_gyrox', 'std_gyroy', 'std_gyroz', 'std_pitch', 'std_roll', 'std_yaw', 'median_x', 'median_y', 'median_z', 'median_gyrox', 'median_gyroy', 'median_gyroz', 'median_pitch', 'median_roll', 'median_yaw', 'mad_x', 'mad_y', 'mad_z', 'mad_gyrox', 'mad_gyroy', 'mad_gyroz', 'mad_pitch', 'mad_roll', 'mad_yaw', 'max_x', 'max_y', 'max_z', 'max_gyrox', 'max_gyroy', 'max_gyroz', 'max_pitch', 'max_roll', 'max_yaw', 'kur_x', 'kur_y', 'kur_z', 'kur_gyrox', 'kur_gyroy', 'kur_gyroz', 'kur_pitch', 'kur_roll', 'kur_yaw', 'skw_x', 'skw_y', 'skw_z', 'skw_gyrox', 'skw_gyroy', 'skw_gyroz', 'skw_pitch', 'skw_roll', 'skw_yaw', 'var_x', 'var_y', 'var_z', 'var_gyrox', 'var_gyroy', 'var_gyroz', 'var_pitch', 'var_roll', 'var_yaw', 'min_x', 'min_y', 'min_z', 'min_gyrox', 'min_gyroy', 'min_gyroz', 'min_pitch', 'min_roll', 'min_yaw', 'mean_x_0', 'mean_y_0', 'mean_z_0', 'mean_gyrox_0', 'mean_gyroy_0', 'mean_gyroz_0', 'mean_pitch_0', 'mean_roll_0', 'mean_yaw_0', 'std_x_0', 'std_y_0', 'std_z_0', 'std_gyrox_0', 'std_gyroy_0', 'std_gyroz_0', 'std_pitch_0', 'std_roll_0', 'std_yaw_0', 'median_x_0', 'median_y_0', 'median_z_0', 'median_gyrox_0', 'median_gyroy_0', 'median_gyroz_0', 'median_pitch_0', 'median_roll_0', 'median_yaw_0', 'mad_x_0', 'mad_y_0', 'mad_z_0', 'mad_gyrox_0', 'mad_gyroy_0', 'mad_gyroz_0', 'mad_pitch_0', 'mad_roll_0', 'mad_yaw_0', 'max_x_0', 'max_y_0', 'max_z_0', 'max_gyrox_0', 'max_gyroy_0', 'max_gyroz_0', 'max_pitch_0', 'max_roll_0', 'max_yaw_0', 'kur_x_0', 'kur_y_0', 'kur_z_0', 'kur_gyrox_0', 'kur_gyroy_0', 'kur_gyroz_0', 'kur_pitch_0', 'kur_roll_0', 'kur_yaw_0', 'skw_x_0', 'skw_y_0', 'skw_z_0', 'skw_gyrox_0', 'skw_gyroy_0', 'skw_gyroz_0', 'skw_pitch_0', 'skw_roll_0', 'skw_yaw_0', 'var_x_0', 'var_y_0', 'var_z_0', 'var_gyrox_0', 'var_gyroy_0', 'var_gyroz_0', 'var_pitch_0', 'var_roll_0', 'var_yaw_0', 'min_x_0', 'min_y_0', 'min_z_0', 'min_gyrox_0', 'min_gyroy_0', 'min_gyroz_0', 'min_pitch_0', 'min_roll_0', 'min_yaw_0', 'mean_x_1', 'mean_y_1', 'mean_z_1', 'mean_gyrox_1', 'mean_gyroy_1', 'mean_gyroz_1', 'mean_pitch_1', 'mean_roll_1', 'mean_yaw_1', 'std_x_1', 'std_y_1', 'std_z_1', 'std_gyrox_1', 'std_gyroy_1', 'std_gyroz_1', 'std_pitch_1', 'std_roll_1', 'std_yaw_1', 'median_x_1', 'median_y_1', 'median_z_1', 'median_gyrox_1', 'median_gyroy_1', 'median_gyroz_1', 'median_pitch_1', 'median_roll_1', 'median_yaw_1', 'mad_x_1', 'mad_y_1', 'mad_z_1', 'mad_gyrox_1', 'mad_gyroy_1', 'mad_gyroz_1', 'mad_pitch_1', 'mad_roll_1', 'mad_yaw_1', 'max_x_1', 'max_y_1', 'max_z_1', 'max_gyrox_1', 'max_gyroy_1', 'max_gyroz_1', 'max_pitch_1', 'max_roll_1', 'max_yaw_1', 'kur_x_1', 'kur_y_1', 'kur_z_1', 'kur_gyrox_1', 'kur_gyroy_1', 'kur_gyroz_1', 'kur_pitch_1', 'kur_roll_1', 'kur_yaw_1', 'skw_x_1', 'skw_y_1', 'skw_z_1', 'skw_gyrox_1', 'skw_gyroy_1', 'skw_gyroz_1', 'skw_pitch_1', 'skw_roll_1', 'skw_yaw_1', 'var_x_1', 'var_y_1', 'var_z_1', 'var_gyrox_1', 'var_gyroy_1', 'var_gyroz_1', 'var_pitch_1', 'var_roll_1', 'var_yaw_1', 'min_x_1', 'min_y_1', 'min_z_1', 'min_gyrox_1', 'min_gyroy_1', 'min_gyroz_1', 'min_pitch_1', 'min_roll_1', 'min_yaw_1', 'mean_x_2', 'mean_y_2', 'mean_z_2', 'mean_gyrox_2', 'mean_gyroy_2', 'mean_gyroz_2', 'mean_pitch_2', 'mean_roll_2', 'mean_yaw_2', 'std_x_2', 'std_y_2', 'std_z_2', 'std_gyrox_2', 'std_gyroy_2', 'std_gyroz_2', 'std_pitch_2', 'std_roll_2', 'std_yaw_2', 'median_x_2', 'median_y_2', 'median_z_2', 'median_gyrox_2', 'median_gyroy_2', 'median_gyroz_2', 'median_pitch_2', 'median_roll_2', 'median_yaw_2', 'mad_x_2', 'mad_y_2', 'mad_z_2', 'mad_gyrox_2', 'mad_gyroy_2', 'mad_gyroz_2', 'mad_pitch_2', 'mad_roll_2', 'mad_yaw_2', 'max_x_2', 'max_y_2', 'max_z_2', 'max_gyrox_2', 'max_gyroy_2', 'max_gyroz_2', 'max_pitch_2', 'max_roll_2', 'max_yaw_2', 'kur_x_2', 'kur_y_2', 'kur_z_2', 'kur_gyrox_2', 'kur_gyroy_2', 'kur_gyroz_2', 'kur_pitch_2', 'kur_roll_2', 'kur_yaw_2', 'skw_x_2', 'skw_y_2', 'skw_z_2', 'skw_gyrox_2', 'skw_gyroy_2', 'skw_gyroz_2', 'skw_pitch_2', 'skw_roll_2', 'skw_yaw_2', 'var_x_2', 'var_y_2', 'var_z_2', 'var_gyrox_2', 'var_gyroy_2', 'var_gyroz_2', 'var_pitch_2', 'var_roll_2', 'var_yaw_2', 'min_x_2', 'min_y_2', 'min_z_2', 'min_gyrox_2', 'min_gyroy_2', 'min_gyroz_2', 'min_pitch_2', 'min_roll_2', 'min_yaw_2', 'mean_x_3', 'mean_y_3', 'mean_z_3', 'mean_gyrox_3', 'mean_gyroy_3', 'mean_gyroz_3', 'mean_pitch_3', 'mean_roll_3', 'mean_yaw_3', 'std_x_3', 'std_y_3', 'std_z_3', 'std_gyrox_3', 'std_gyroy_3', 'std_gyroz_3', 'std_pitch_3', 'std_roll_3', 'std_yaw_3', 'median_x_3', 'median_y_3', 'median_z_3', 'median_gyrox_3', 'median_gyroy_3', 'median_gyroz_3', 'median_pitch_3', 'median_roll_3', 'median_yaw_3', 'mad_x_3', 'mad_y_3', 'mad_z_3', 'mad_gyrox_3', 'mad_gyroy_3', 'mad_gyroz_3', 'mad_pitch_3', 'mad_roll_3', 'mad_yaw_3', 'max_x_3', 'max_y_3', 'max_z_3', 'max_gyrox_3', 'max_gyroy_3', 'max_gyroz_3', 'max_pitch_3', 'max_roll_3', 'max_yaw_3', 'kur_x_3', 'kur_y_3', 'kur_z_3', 'kur_gyrox_3', 'kur_gyroy_3', 'kur_gyroz_3', 'kur_pitch_3', 'kur_roll_3', 'kur_yaw_3', 'skw_x_3', 'skw_y_3', 'skw_z_3', 'skw_gyrox_3', 'skw_gyroy_3', 'skw_gyroz_3', 'skw_pitch_3', 'skw_roll_3', 'skw_yaw_3', 'var_x_3', 'var_y_3', 'var_z_3', 'var_gyrox_3', 'var_gyroy_3', 'var_gyroz_3', 'var_pitch_3', 'var_roll_3', 'var_yaw_3', 'min_x_3', 'min_y_3', 'min_z_3', 'min_gyrox_3', 'min_gyroy_3', 'min_gyroz_3', 'min_pitch_3', 'min_roll_3', 'min_yaw_3', 'mean_x_4', 'mean_y_4', 'mean_z_4', 'mean_gyrox_4', 'mean_gyroy_4', 'mean_gyroz_4', 'mean_pitch_4', 'mean_roll_4', 'mean_yaw_4', 'std_x_4', 'std_y_4', 'std_z_4', 'std_gyrox_4', 'std_gyroy_4', 'std_gyroz_4', 'std_pitch_4', 'std_roll_4', 'std_yaw_4', 'median_x_4', 'median_y_4', 'median_z_4', 'median_gyrox_4', 'median_gyroy_4', 'median_gyroz_4', 'median_pitch_4', 'median_roll_4', 'median_yaw_4', 'mad_x_4', 'mad_y_4', 'mad_z_4', 'mad_gyrox_4', 'mad_gyroy_4', 'mad_gyroz_4', 'mad_pitch_4', 'mad_roll_4', 'mad_yaw_4', 'max_x_4', 'max_y_4', 'max_z_4', 'max_gyrox_4', 'max_gyroy_4', 'max_gyroz_4', 'max_pitch_4', 'max_roll_4', 'max_yaw_4', 'kur_x_4', 'kur_y_4', 'kur_z_4', 'kur_gyrox_4', 'kur_gyroy_4', 'kur_gyroz_4', 'kur_pitch_4', 'kur_roll_4', 'kur_yaw_4', 'skw_x_4', 'skw_y_4', 'skw_z_4', 'skw_gyrox_4', 'skw_gyroy_4', 'skw_gyroz_4', 'skw_pitch_4', 'skw_roll_4', 'skw_yaw_4', 'var_x_4', 'var_y_4', 'var_z_4', 'var_gyrox_4', 'var_gyroy_4', 'var_gyroz_4', 'var_pitch_4', 'var_roll_4', 'var_yaw_4', 'min_x_4', 'min_y_4', 'min_z_4', 'min_gyrox_4', 'min_gyroy_4', 'min_gyroz_4', 'min_pitch_4', 'min_roll_4', 'min_yaw_4']\n"
     ]
    }
   ],
   "source": [
    "#%%timeit \n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "\n",
    "\n",
    "number_of_segments=n_splits\n",
    "\n",
    "#Check if the input for n_splits is is greater than 1(signal is divided in n_splits ) or not (signal is not divided)\n",
    "if number_of_segments <= 1:\n",
    "    segments=False #No segmentation is done\n",
    "else:\n",
    "    segments=True #Signal divided in n segments\n",
    "    \n",
    "    \n",
    "#Feature table for all classes\n",
    "wrist_df = gather(wrist_class,segments=segments,split_index=number_of_segments)\n",
    "\n",
    "#Extact number of the class (feature Y)\n",
    "wrist_Y = np.asarray(wrist_df.Y)\n",
    "n_samples=len(wrist_Y)\n",
    "\n",
    "#Total number of features\n",
    "num_features=len(wrist_df.columns)-1\n",
    "print ('Total features: {}'.format(num_features))\n",
    "#Extact rest of colums (features)\n",
    "wrist_X = np.asarray(wrist_df.iloc[:,:num_features])\n",
    "wrist_X_df = pd.DataFrame(wrist_X, columns=(wrist_df.iloc[:,:num_features]).columns)\n",
    "\n",
    "#Maxium number of available features\n",
    "all_features = num_features \n",
    "print (\"Feature names  \" + str(wrist_df.iloc[:,:num_features].columns.values.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data processing without subwindows\n",
    "\n",
    "when segments = False\n",
    "\n",
    "Each sequence of data is considered as a unique window. Features are calculated for that window."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#%%timeit \n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "\n",
    "number_of_segments=1\n",
    "if number_of_segments <= 1:\n",
    "    segments=False\n",
    "else:\n",
    "    segments=True\n",
    "\n",
    "    \n",
    "#Feature table for all classes\n",
    "wrist_df_NO_S = gather(wrist_class,segments=segments,split_index=number_of_segments)\n",
    "#Extact number of the class (feature Y)\n",
    "wrist_Y = np.asarray(wrist_df.Y)\n",
    "\n",
    "#Total number of features\n",
    "num_features_NO_S=len(wrist_df_NO_S.columns)-1\n",
    "print ('Total features: {}'.format(num_features_NO_S))\n",
    "#Extact rest of colums (features)\n",
    "wrist_X_NO_S = np.asarray(wrist_df_NO_S.iloc[:,:num_features_NO_S])\n",
    "\n",
    "#Maxium number of available features\n",
    "all_features = num_features \n",
    "print (\"Feature names  \" + str(wrist_df_NO_S.iloc[:,:num_features].columns.values.tolist()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "\n",
    "Run the corresponding cell to perform the analysis based on the corresponding classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression (LG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LG\n",
    "n=0\n",
    "alg_array = [LogisticRegression(random_state=n)] \n",
    "alg_array_names  = ['LG']\n",
    "item_name=\"LG\"\n",
    "item=LogisticRegression(random_state=n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest  (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=0)\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "n=0\n",
    "alg_array = [RandomForestClassifier(verbose= 0,n_estimators= 100,random_state= n)]\n",
    "alg_array_names  = ['RF']\n",
    "item_name=\"RF\"\n",
    "item=RandomForestClassifier(verbose= 0,n_estimators= 100,random_state= n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN -> AÑADIDOS MÁS N\n",
    "n=0\n",
    "alg_array = [KNeighborsClassifier(n_neighbors=3)]\n",
    "alg_array_names  = ['KNN']\n",
    "item_name=\"KNN\"\n",
    "item=KNeighborsClassifier(n_neighbors=3)\n",
    "             \n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB\n",
    "n=0\n",
    "alg_array = [ GaussianNB()]\n",
    "alg_array_names  = ['NB']\n",
    "item_name=\"NB\"\n",
    "item=GaussianNB()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "n=0\n",
    "alg_array = [svm.SVC(kernel='linear', C=64.0, random_state=n, probability=True)]\n",
    "alg_array_names  = ['SVM']\n",
    "item_name=\"SVM\"\n",
    "item=svm.SVC(kernel='linear', C=64.0, random_state=n, probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptron (MP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "n=0\n",
    "alg_array = [MLPClassifier(hidden_layer_sizes=(16, 16, 16), max_iter=1000, random_state=n)]\n",
    "alg_array_names  = ['MLP']\n",
    "item_name=\"MLP\"\n",
    "item=MLPClassifier(hidden_layer_sizes=(16, 16, 16), max_iter=1000, random_state=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refence classfier\n",
    "\n",
    "Reference results for the more complex model (trained using all the available features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------- \n",
      "---Number of Features 486-----\n",
      "----------------------------- \n",
      "\n",
      "\n",
      "LogisticRegression(random_state=0)\n",
      "########### LG ##########\n",
      "recall_macro - 87.79 (SD 0.744)\n",
      "precision_macro - 87.79 (SD 0.628)\n",
      "f1_macro - 87.69 (SD 0.708)\n",
      "accuracy - 89.37 (SD 0.524)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ref_score=[]\n",
    "scoring = ['recall_macro','precision_macro','f1_macro','accuracy']\n",
    "\n",
    "\n",
    "for n_features in best_features_num:\n",
    "    select_feature = SelectKBest(chi2, k=n_features)\n",
    "    print ('----------------------------- ')\n",
    "    print ('---Number of Features %0.0f-----' % n_features)\n",
    "    print ('----------------------------- ')\n",
    "    print('\\n')\n",
    "\n",
    "    for item, item_name in zip(alg_array, alg_array_names): \n",
    "        print ('########### ' + str(item_name) + ' ##########\\n')\n",
    "        for score in scoring:\n",
    "            pipe = Pipeline([('Maxmin', preprocessing.MinMaxScaler()),\n",
    "                             ('Feature selection',select_feature), ('Algorithm',item)])\n",
    "\n",
    "            for n in range(0,n_times):\n",
    "                kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=n)\n",
    "                scores = cross_val_score(pipe, wrist_X, wrist_Y, cv =kf, scoring = score)\n",
    "                features = pipe.named_steps['Feature selection']\n",
    "                average_score = (np.mean(scores)*100)\n",
    "                ref_score.append(average_score)\n",
    "            \n",
    "            \n",
    "            #print (array_dict_pre[item_name])\n",
    "            #print (str(score) + ' - ' + ' MEAN  '  + str(np.mean(array_dict_pre[item_name])) + ' - SD '+ str(np.std(array_dict_pre[item_name])))\n",
    "            #print (str(score) + ' - ' + ' MEAN  ' + '%.2f '  + ' - SD ' +  '%.3f ' % (np.mean(array_dict_pre[item_name]), np.std(array_dict_pre[item_name])))\n",
    "            print(str(score) + ' - ' '%.2f (SD %.3f)' % (np.mean(ref_score), np.std(ref_score)))\n",
    "            ref_score=[]\n",
    "        \n",
    "        print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensemble techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staking\n",
      "\n",
      "ALG   LogisticRegression(random_state=0)\n",
      "\n",
      "87.58 (SD 0.900)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_n_times=[]\n",
    "\n",
    "print(\"Staking\\n\")\n",
    "print(\"ALG   \"+str(item)+\"\\n\")\n",
    "for n in range(0,n_times):\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle = True, random_state=n)    \n",
    "    select_feature_1 = SelectKBest(chi2, k=n_features_m1)\n",
    "    select_feature_2 = SelectKBest(chi2, k=n_features_m2)\n",
    "    select_feature_3 = SelectKBest(chi2, k=n_features_m3)\n",
    "    \n",
    "    #Definition of the models that constitutes the stacking ensemble\n",
    "    estimators = [\n",
    "    ('10_features', Pipeline([('Maxmin', preprocessing.MinMaxScaler()),\n",
    "                ('Feature selection',select_feature_1),\n",
    "                                ('Algorithm',item)])),\n",
    "    ('50_features', Pipeline([('Maxmin', preprocessing.MinMaxScaler()),\n",
    "                ('Feature selection',select_feature_2),\n",
    "                                ('Algorithm',item)])),\n",
    "    ('486_features', Pipeline([('Maxmin', preprocessing.MinMaxScaler()),\n",
    "                ('Feature selection',select_feature_3),\n",
    "                                ('Algorithm',item)]))]\n",
    "\n",
    "    clf = StackingClassifier(estimators=estimators, final_estimator=item, n_jobs=-1)\n",
    "    pred=cross_val_predict(clf, wrist_X, wrist_Y, cv =kf)\n",
    "    results_1 = cross_val_score(clf, wrist_X, wrist_Y, cv=kf, scoring = \"f1_macro\")\n",
    "    results_n_times.append(results_1.mean())\n",
    "\n",
    "\n",
    "\n",
    "print('%.2f (SD %.3f)' % (np.mean(results_n_times)*100, np.std(results_n_times)*100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CASCADE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_classes=np.unique(wrist_Y, return_index=False, return_inverse=False, return_counts=False, axis=None)\n",
    "start=values_classes[0]\n",
    "\n",
    "#Multiclass log loss\n",
    "def multiclass_log_loss(y_true, y_pred,eps=1e-15):\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    return -(y_true * np.log(y_pred)).sum(axis=1)\n",
    "\n",
    "#Check the definition of the segments statement and select the initial feature matrix accordingly\n",
    "def check_segments(segments):\n",
    "    if segments==True:\n",
    "        X=wrist_X #Feature matrix with segments\n",
    "    else:\n",
    "        X=wrist_X_NO_S #Feature matrix whitout segments\n",
    "    return X\n",
    "\n",
    "\n",
    "#Check if any element is missing in the probabilities of prediction array to avoid errors\n",
    "def missing_elements(L, labels, Y):\n",
    "    global start\n",
    "    #start, end = Y[0], L[-1]\n",
    "    end = Y[0]\n",
    "    if start==0:\n",
    "        sort=sorted(set(range(0, len(labels))).difference(L))\n",
    "        for i in sort:\n",
    "            if i == end:\n",
    "                i=0\n",
    "    else:\n",
    "        sort=sorted(set(range(1, len(labels)+ 1)).difference(L))\n",
    "    return sort\n",
    "\n",
    "\n",
    "#Chech if the number of remaining instances is enough to perform a 5-CV \n",
    "def check_CV_instances(Y):\n",
    "    unique, counts = np.unique(Y, return_counts=True)\n",
    "    j=0\n",
    "    return_=False\n",
    "    for i in counts:\n",
    "        if i == 1:\n",
    "            j=j+1\n",
    "            if j == 2:\n",
    "                return_ = True\n",
    "    return return_\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "#Class to binarize the obtained prediction value to have a binary array instead of an integer value\n",
    "class LabelBinarizer2:\n",
    "    def __init__(self):\n",
    "        self.lb = LabelBinarizer()\n",
    "    def fit(self, X):\n",
    "        # Convert X to array\n",
    "        X = np.array(X)\n",
    "        # Fit X using the LabelBinarizer object\n",
    "        self.lb.fit(X)\n",
    "        # Save the classes\n",
    "        self.classes_ = self.lb.classes_\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        # Convert X to array\n",
    "        X = np.array(X)\n",
    "        # Fit + transform X using the LabelBinarizer object\n",
    "        Xlb = self.lb.fit_transform(X)\n",
    "        # Save the classes\n",
    "        self.classes_ = self.lb.classes_\n",
    "        if len(self.classes_) == 2:\n",
    "            Xlb = np.hstack((Xlb, 1 - Xlb))\n",
    "        return Xlb\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Convert X to array\n",
    "        X = np.array(X)\n",
    "        # Transform X using the LabelBinarizer object\n",
    "        Xlb = self.lb.transform(X)\n",
    "        if len(self.classes_) == 2:\n",
    "            Xlb = np.hstack((Xlb, 1 - Xlb))\n",
    "        return Xlb\n",
    "\n",
    "    def inverse_transform(self, Xlb):\n",
    "        # Convert Xlb to array\n",
    "        Xlb = np.array(Xlb)\n",
    "        if len(self.classes_) == 2:\n",
    "            X = self.lb.inverse_transform(Xlb[:, 0])\n",
    "        else:\n",
    "            X = self.lb.inverse_transform(Xlb)\n",
    "        return X\n",
    "            \n",
    "        \n",
    "#Fill the gaps in incomplete arrays\n",
    "def complete_arrays (Y,pred,pred_binarized,proba,labels):\n",
    "    global start\n",
    "    values_classes=np.unique(pred, return_index=False, return_inverse=False, return_counts=False, axis=None)\n",
    "    miss = missing_elements(values_classes,wrist_labels,Y)\n",
    "    for i in miss: \n",
    "        if start==0:\n",
    "            i=i\n",
    "        else:\n",
    "            i=i-1\n",
    "        pred_binarized=np.hstack((pred_binarized[:,:i], np.zeros((pred_binarized.shape[0], 1)), pred_binarized[:,i:]))\n",
    "\n",
    "    #Check if some class is missing in probabilities\n",
    "    values_classes=np.unique(Y, return_index=False, return_inverse=False, return_counts=False, axis=None)\n",
    "    columns=labels\n",
    "    df = pd.DataFrame()\n",
    "    j=0\n",
    "    for i in  values_classes:\n",
    "        if start==0:\n",
    "            i=i\n",
    "        else:\n",
    "            i=i-1\n",
    "        if int(i)>int(j):\n",
    "            df.insert(int(j), column=columns[int(i)], value=proba[:,int(j)])\n",
    "        else:\n",
    "            df.insert(int(j), column=columns[int(i)], value=proba[:,int(i)])\n",
    "        j=j+1\n",
    "\n",
    "            \n",
    "    miss = missing_elements(values_classes,columns, wrist_Y)\n",
    "    \n",
    "    #include missing probabilities\n",
    "    for i in miss: \n",
    "        if start==0:\n",
    "            i=i\n",
    "        else:\n",
    "            i=i-1\n",
    "        df.insert(int(i), column=columns[int(i)], value=np.zeros(len(proba[:,int(0)])))\n",
    "\n",
    "    proba=df.values\n",
    "    return pred_binarized, proba, df\n",
    "\n",
    "\n",
    "#Perfom the classification process for one stage of the model cascade for the secuential implementation\n",
    "def classif_model(pipe,wrist_X,wrist_Y,log_loss_T,final_model):\n",
    "    global n_samples\n",
    "    global start\n",
    "    score_selection=[]\n",
    "    \n",
    "    #Obtain the probability and prediction of an intance\n",
    "    proba = cross_val_predict(pipe, wrist_X, wrist_Y, cv =kf, method='predict_proba')\n",
    "    pred = cross_val_predict(pipe, wrist_X, wrist_Y, cv =kf)\n",
    "\n",
    "    #Label binarization\n",
    "    lb = LabelBinarizer2()\n",
    "    wrist_Y_binarized = lb.fit_transform(wrist_Y)\n",
    "    pred_binarized = lb.fit_transform(pred)\n",
    "\n",
    "    #Check and add missing elements\n",
    "    pred_binarized, proba, df = complete_arrays(wrist_Y,pred,pred_binarized,proba,wrist_labels)\n",
    "\n",
    "    #Obtain log loss value\n",
    "    ll_pred = multiclass_log_loss(pred_binarized, proba)\n",
    "\n",
    "    #Create dataframe containing all the information about classified instances\n",
    "    df3 = pd.DataFrame(pred,columns=['Pred_label'])\n",
    "    df2 = pd.DataFrame(wrist_Y,columns=['True_label'])\n",
    "    df = pd.DataFrame(proba,columns=labels)\n",
    "    df=df.join(df2)\n",
    "    df=df.join(df3)\n",
    "    df5 =pd.DataFrame(ll_pred, columns=[\"LOG_LOSS\"])\n",
    "    df=df.join(df5)\n",
    "\n",
    "    #Add new colum to the Dataframe containing the new predictions based on calculated threshold\n",
    "    df['Error_thres'] = np.where(df['Pred_label'] == df['True_label'], '_', 'TRUE')\n",
    "\n",
    "    #Compare the confidence threshold to obtain the pending and classified instances with \n",
    "    if final_model == False: #n-1 level of the cascade\n",
    "        df_thres_NO_S=df[(df.LOG_LOSS <= log_loss_T)] #Clasificados\n",
    "        df_pending_NO_S=df[(df.LOG_LOSS >= log_loss_T)] #Pending\n",
    "        n_samples=((df_pending_NO_S.shape)[0])\n",
    "\n",
    "        selection= df_thres_NO_S.shape[0]\n",
    "        index_selection= df_pending_NO_S.index.values.tolist()\n",
    "                \n",
    "        errors_selection= df_thres_NO_S[(df_thres_NO_S.Error_thres == 'TRUE')].shape[0]\n",
    "        score_selection= f1_score(df_thres_NO_S[\"True_label\"].values, df_thres_NO_S[\"Pred_label\"].values, average=\"macro\")\n",
    "\n",
    "        #check if the number of pending instances is enouch to perform the 5-CV process\n",
    "        if len(df_thres_NO_S.index.values.tolist()) > 0:\n",
    "            clasif_report= classification_report(df_thres_NO_S[\"True_label\"].values, df_thres_NO_S[\"Pred_label\"].values, digits=4)\n",
    "        else:\n",
    "            clasif_report=[]\n",
    "            #print(\"Not enough instances to classify with model\")\n",
    "    else: #Last level of the cascade\n",
    "        clasif_report=classification_report(df[\"True_label\"].values, df[\"Pred_label\"].values, digits=4)\n",
    "        df_thres_NO_S=df.copy()\n",
    "        errors_selection= df_thres_NO_S[(df_thres_NO_S.Error_thres == 'TRUE')].shape[0]\n",
    "        score_selection= f1_score(df_thres_NO_S[\"True_label\"].values, df_thres_NO_S[\"Pred_label\"].values, average=\"macro\")\n",
    "        index_selection=[]\n",
    "    return(index_selection,df_thres_NO_S,clasif_report,errors_selection,score_selection)\n",
    "\n",
    "\n",
    "\n",
    "#Perfom the classification process for one stage of the model cascade for paralel implementation\n",
    "def classif_model_paralel(pipe,wrist_X,wrist_Y,log_loss_T,final_model,model_2):\n",
    "    global n_samples\n",
    "    global index_selection_M1, index_selection_M2\n",
    "\n",
    "    score_selection=[]\n",
    "    \n",
    "    #Obtain the probability and prediction of an intance\n",
    "    proba = cross_val_predict(pipe, wrist_X, wrist_Y, cv =kf, method='predict_proba')\n",
    "    pred = cross_val_predict(pipe, wrist_X, wrist_Y, cv =kf)\n",
    "\n",
    "    #Label binarization\n",
    "    lb = LabelBinarizer2()\n",
    "    wrist_Y_binarized = lb.fit_transform(wrist_Y)\n",
    "    pred_binarized = lb.fit_transform(pred)\n",
    "\n",
    "    pred_binarized, proba, df = complete_arrays(wrist_Y,pred,pred_binarized,proba,wrist_labels)\n",
    "\n",
    "    \n",
    "    ll_pred = multiclass_log_loss(pred_binarized, proba)\n",
    "\n",
    "    if model_2==True: #n-1 level\n",
    "        pred=pred[index_selection_M1]\n",
    "        proba=proba[index_selection_M1]\n",
    "        ll_pred=ll_pred[index_selection_M1]\n",
    "        wrist_Y=wrist_Y[index_selection_M1]\n",
    "            \n",
    "    elif final_model == True: #Final level cascade\n",
    "        pred_selection=pred[index_selection_M1]\n",
    "        pred=pred_selection[index_selection_M2]\n",
    "\n",
    "        proba_selection=proba[index_selection_M1]\n",
    "        proba=proba_selection[index_selection_M2]\n",
    "\n",
    "        wrist_Y_selection=wrist_Y[index_selection_M1]\n",
    "        wrist_Y=wrist_Y_selection[index_selection_M2]\n",
    " \n",
    "\n",
    "        ll_pred_m3_selection=ll_pred[index_selection_M1]\n",
    "        ll_pred=ll_pred_m3_selection[index_selection_M2]\n",
    "\n",
    "\n",
    "    \n",
    "    #Dataframe \n",
    "    df3 = pd.DataFrame(pred,columns=['Pred_label'])\n",
    "    df2 = pd.DataFrame(wrist_Y,columns=['True_label'])\n",
    "    df = pd.DataFrame(proba,columns=labels)\n",
    "    df=df.join(df2)\n",
    "    df=df.join(df3)\n",
    "    df5 =pd.DataFrame(ll_pred, columns=[\"LOG_LOSS\"])\n",
    "    df=df.join(df5)\n",
    "\n",
    "    #Add new colum to the Dataframe containing the new predictions based on calculated threshold\n",
    "    df['Error_thres'] = np.where(df['Pred_label'] == df['True_label'], '_', 'TRUE')\n",
    "\n",
    "    if final_model == False:\n",
    "        df_thres_NO_S=df[(df.LOG_LOSS <= log_loss_T)] #Clasificados\n",
    "        df_pending_NO_S=df[(df.LOG_LOSS >= log_loss_T)] #Pending\n",
    "        n_samples=((df_pending_NO_S.shape)[0])\n",
    "        selection= df_thres_NO_S.shape[0]\n",
    "        index_selection= df_pending_NO_S.index.values.tolist()\n",
    "        \n",
    "        if model_2==False:\n",
    "            #If model 1, save indexes\n",
    "            index_selection_M1=df_pending_NO_S.index.values.tolist()\n",
    "        else:\n",
    "            #If model 2, save indexes\n",
    "            index_selection_M2=df_pending_NO_S.index.values.tolist()\n",
    "            \n",
    "        errors_selection= df_thres_NO_S[(df_thres_NO_S.Error_thres == 'TRUE')].shape[0]\n",
    "        score_selection= f1_score(df_thres_NO_S[\"True_label\"].values, df_thres_NO_S[\"Pred_label\"].values, average=\"macro\")\n",
    "        #check if the number of pending instances is enouch to perform the 5-CV process\n",
    "        if len(df_thres_NO_S.index.values.tolist()) > 0:\n",
    "            clasif_report= classification_report(df_thres_NO_S[\"True_label\"].values, df_thres_NO_S[\"Pred_label\"].values, digits=4)\n",
    "            #print(clasif_report)\n",
    "        else:\n",
    "            classif_report=[]\n",
    "            #print(\"Not enough instances to classify with model 2\")\n",
    "    else:\n",
    "        clasif_report=classification_report(df[\"True_label\"].values, df[\"Pred_label\"].values, digits=4)\n",
    "        df_thres_NO_S=df.copy()\n",
    "        errors_selection= df_thres_NO_S[(df_thres_NO_S.Error_thres == 'TRUE')].shape[0]\n",
    "        score_selection= f1_score(df_thres_NO_S[\"True_label\"].values, df_thres_NO_S[\"Pred_label\"].values, average=\"macro\")\n",
    "        index_selection=[]\n",
    "        #print(clasif_report)\n",
    "        \n",
    "\n",
    "    return(index_selection,df_thres_NO_S,clasif_report,errors_selection,score_selection)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todas clasificadas - Secuencial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________SECUENCIAL__________________\n",
      "\n",
      "--------------------------------------------------------------\n",
      "--- Number of Features Model 1: 10 Feat. - Model 2: 50 Feat. - Model 3: 486 Feat.   ---\n",
      "--------------------------------------------------------------\n",
      "\n",
      "\n",
      "########### LG ##########\n",
      " \n",
      " Model 1 \n",
      "\n",
      " \n",
      "Initial Mean F1_macro: 0.666539879844612\n",
      "Mean Selection: 305.3 - out of 1000\n",
      "Mean Number of errores selection: 6.1\n",
      "Mean F1_macro selection: 0.623391531517089\n",
      "Clasification report final M1 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    0.9885    0.9942       262\n",
      "         1.0     0.0000    0.0000    0.0000         2\n",
      "         2.0     0.8000    1.0000    0.8889        20\n",
      "\n",
      "    accuracy                         0.9824       284\n",
      "   macro avg     0.6000    0.6628    0.6277       284\n",
      "weighted avg     0.9789    0.9824    0.9798       284\n",
      "\n",
      " \n",
      " Model 2 \n",
      "\n",
      " \n",
      "Initial Mean F1_macro: 0.7946448041983922\n",
      "Mean Selection: 398.9 out of 694.7\n",
      "Mean Number of errores selection: 38.9\n",
      "Mean F1_macro selection: 0.8958420686109996\n",
      "Mean F1_macro for M1 + M2: 0.9073827504296192\n",
      "Clasification report final M2 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9769    0.8989    0.9363       188\n",
      "         1.0     0.8352    0.8636    0.8492        88\n",
      "         2.0     0.8786    0.9609    0.9179       128\n",
      "\n",
      "    accuracy                         0.9109       404\n",
      "   macro avg     0.8969    0.9078    0.9011       404\n",
      "weighted avg     0.9149    0.9109    0.9115       404\n",
      "\n",
      "\n",
      " Final \n",
      "\n",
      "\n",
      "Final Mean F1_macro: 86.69503436968735 - SD 0.5607319741427771\n",
      "86.70 (SD 0.561)\n",
      "Classified: 1000.0 /  Not classified 0.0\n",
      "Classified Before Final stage: 704.2- SD 19.81817347789649 /  Not classified 295.79999999999995\n",
      "Mean Number of errors selection: 45.0\n",
      "\n",
      " Clasification report final SELECTION \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other     0.9663    0.9052    0.9348      5200\n",
      " Drink_glass     0.8111    0.8462    0.8283      2400\n",
      "Drink_bottle     0.8019    0.8771    0.8378      2400\n",
      "\n",
      "    accuracy                         0.8843     10000\n",
      "   macro avg     0.8598    0.8762    0.8670     10000\n",
      "weighted avg     0.8896    0.8843    0.8859     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selection_M1_array = [] #Selection M1\n",
    "errors_selection_M1_array = [] # Errors_selection M1\n",
    "score_selection_M1_array = [] #score selection M1\n",
    "selection_M2_array= [] #Selection M2\n",
    "errors_selection_M2_array = [] # errorsSelection M2\n",
    "score_selection_M2_array= [] #score selection M2\n",
    "index_selection=[]\n",
    "wrist_X_new=[]\n",
    "wrist_Y_new=[]\n",
    "wrist_X_selection=[]\n",
    "wrist_Y_selection=[]\n",
    "wrist_X_NO_S_new=[]\n",
    "wrist_Y_NO_S_new=[]\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "original_class = []\n",
    "predicted_class = []\n",
    "original_class_M2 = []\n",
    "predicted_clas_M2s = []\n",
    "original_class_M2 = []\n",
    "predicted_class_M2 = []\n",
    "score_final =[]\n",
    "score_final_M2 =[]\n",
    "final_selection=[]\n",
    "final_selection_before_M3=[]\n",
    "initial_scores=[]\n",
    "initial_scores_M1=[]\n",
    "initial_scores_M2=[]\n",
    "initial_scores_M2_all=[]\n",
    "initial_scores_M3=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"__________________SECUENCIAL__________________\\n\")\n",
    "\n",
    "print ('--------------------------------------------------------------')\n",
    "print ('--- Number of Features Model 1: %0.0f Feat. - Model 2: %0.0f Feat. - Model 3: %0.0f Feat.   ---' % (n_features_m1, n_features_m2, n_features_m3))\n",
    "print ('--------------------------------------------------------------')\n",
    "print('\\n')\n",
    "\n",
    "for item, item_name in zip(alg_array, alg_array_names): \n",
    "    print ('########### ' + str(item_name) + ' ##########')\n",
    "\n",
    "    for n in range(0,n_times):\n",
    "        \n",
    "        #define stratified 5-fold cross validation\n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle = True, random_state=n)\n",
    "        \n",
    "        ###########################################################################################\n",
    "        #--------------------------- MODEL 1 ------------------------------------------------------\n",
    "        ###########################################################################################\n",
    "\n",
    "        #Feature selection definition\n",
    "        select_feature = SelectKBest(chi2, k=n_features_m1)\n",
    "        \n",
    "        #Create pipeline to perform every processing stage only for the training folds of the 5-CV\n",
    "        pipe = Pipeline([('Maxmin', preprocessing.MinMaxScaler()),\n",
    "        ('Feature selection',select_feature),\n",
    "                     ('Algorithm',item)])\n",
    "        \n",
    "        #Select the data input depending on segments true or false\n",
    "        X_data_M1=check_segments(segments_m1)\n",
    "\n",
    "        #Obtain reference score for model 1\n",
    "        scores_M1 = cross_val_score(pipe, X_data_M1, wrist_Y, cv =kf, scoring = 'f1_macro')\n",
    "        initial_scores_M1.append(np.mean(scores_M1))\n",
    "\n",
    "        #Results the fist level of the model cascade\n",
    "        #df_thres_1 dataframe contains the classified instances of model 1\n",
    "        index_selection, df_thres_1,clasif_report_M1,errors_selection_M1,score_selection_M1= classif_model(pipe, X_data_M1 ,wrist_Y, log_loss_T,final_model=False)\n",
    "    \n",
    "        #Classified instances X (for segmented and no segmented data)\n",
    "        if segments_m2==True:\n",
    "            wrist_X_selection_M1=wrist_X[index_selection]\n",
    "        else:\n",
    "            wrist_X_selection_M1=wrist_X_NO_S[index_selection] #pending \n",
    "            wrist_X_selection_M1_segments=wrist_X[index_selection]\n",
    "\n",
    "\n",
    "        #Classified instances Y\n",
    "        wrist_Y_selection_M1=wrist_Y[index_selection] \n",
    "        selection_M1=df_thres_1.shape[0] # Number of instances cassified\n",
    "        \n",
    "        #Create array for averaging results\n",
    "        initial_scores_M1.append(np.mean(scores_M1)) #Reference M1 score array\n",
    "        selection_M1_array.append(selection_M1) #Number of instances cassified M1 array\n",
    "        errors_selection_M1_array.append(errors_selection_M1) #errors selection M1 array\n",
    "        score_selection_M1_array.append(score_selection_M1) #F1 score selection M1 array\n",
    "\n",
    "        \n",
    "        ###########################################################################################\n",
    "        #--------------------------- MODEL 2 ------------------------------------------------------ \n",
    "        ###########################################################################################\n",
    "\n",
    "        #Feature selection definition\n",
    "        select_feature_M2 = SelectKBest(chi2, k=n_features_m2)\n",
    "        \n",
    "        #Create pipeline to perform every processing stage only for the training folds of the 5-CV\n",
    "        pipe2 = Pipeline([('Maxmin', preprocessing.MinMaxScaler()),\n",
    "            ('Feature selection',select_feature_M2), ('Algorithm',item)])\n",
    "\n",
    "        #Select the data input depending on segments true or false\n",
    "        X_data_M2=check_segments(segments_m2)\n",
    "\n",
    "        #Obtain reference score for model 2\n",
    "        scores_M2 = cross_val_score(pipe2, X_data_M2, wrist_Y, cv =kf, scoring = 'f1_macro')\n",
    "        initial_scores_M2.append(np.mean(scores_M2))\n",
    "\n",
    "              \n",
    "        # Check the number of remaining instances to avoid exceptions in the 5CV\n",
    "        if ((n_splits*1.5 < n_samples)and ((check_CV_instances(wrist_Y_selection_M1)== False) or (n_samples > number_classes*2))):\n",
    "            \n",
    "            #Results the second level of the model cascade \n",
    "            #df_thres_2 dataframe contains the classified instances of model 2\n",
    "            index_selection, df_thres_2,clasif_report_M2,errors_selection_M2,score_selection_M2= classif_model(pipe2, wrist_X_selection_M1,wrist_Y_selection_M1,log_loss_T_sel,final_model=False)\n",
    "            \n",
    "\n",
    "            if segments_m2==True: \n",
    "                wrist_X_selection_M2=wrist_X_selection_M1[index_selection] \n",
    "            else: \n",
    "                wrist_X_selection_M2=wrist_X_selection_M1_segments[index_selection] \n",
    "\n",
    "                \n",
    "            #Classified instances\n",
    "            wrist_Y_selection_M2=wrist_Y_selection_M1[index_selection] \n",
    "            selection_M2=df_thres_2.shape[0] #Number of instances cassified\n",
    "\n",
    "            selection_M2_array.append(selection_M2) #Number of instances cassified M2 array\n",
    "            errors_selection_M2_array.append(errors_selection_M2) #errors selection M2 array\n",
    "            score_selection_M2_array.append(score_selection_M2) #F1 score selection M2 array\n",
    "                \n",
    "        else: #If number of remaining instances is not enough for 5-CV\n",
    "            df_thres_2 = pd.DataFrame()\n",
    "            if segments_m2==True: \n",
    "                wrist_X_selection_M2=wrist_X_selection_M1 #pending \n",
    "            else: \n",
    "                wrist_X_selection_M2=wrist_X_selection_M1_segments #pending\n",
    "            wrist_Y_selection_M2=wrist_Y_selection_M1 #pending\n",
    "            selection_M2=0\n",
    "        \n",
    "        #------------------ MODEL 1 + Model 2 --------------------\n",
    "\n",
    "        #Join m1+m2 in one dataframe\n",
    "        M2_all= [df_thres_1, df_thres_2]\n",
    "        final_df_M2 = pd.concat(M2_all)\n",
    "        selection_M2_all=final_df_M2.shape[0]\n",
    "\n",
    "        #results of first two levels (m1 and m2) of the cascade\n",
    "        errors_selection_final_M2= final_df_M2[(final_df_M2.Error_thres == 'TRUE')].shape[0]\n",
    "        score_selection_final_M2= f1_score(final_df_M2[\"True_label\"].values, final_df_M2[\"Pred_label\"].values, average=\"macro\")\n",
    "        score_final_M2.append(score_selection_final_M2)\n",
    "\n",
    "\n",
    "        ###########################################################################################\n",
    "        #--------------------------- MODEL 3 ------------------------------------------------------ \n",
    "        ###########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "        #Feature selection definition\n",
    "        select_feature_M3 = SelectKBest(chi2, k=n_features_m3)\n",
    "        pipe3 = Pipeline([('Maxmin', preprocessing.MinMaxScaler()),\n",
    "            ('Feature selection',select_feature_M3), ('Algorithm',item)])\n",
    "\n",
    "        #Check segments model 3\n",
    "        X_data_M3=check_segments(segments_m3)\n",
    "        X_data_M3\n",
    "\n",
    "        #Obtain reference score model 3\n",
    "        scores_M3 = cross_val_score(pipe3, X_data_M3, wrist_Y, cv =kf, scoring = 'f1_macro')\n",
    "        initial_scores_M3.append(np.mean(scores_M3))\n",
    "              \n",
    "        # Check the number of remaining instances to avoid exceptions in the 5CV\n",
    "        if ((n_splits*1.5 < n_samples)and ((check_CV_instances(wrist_Y_selection_M2)== False) or (n_samples > number_classes*2))):\n",
    "            \n",
    "            #No treshold is applied at the last stage\n",
    "            log_loss_T_sel_3=0\n",
    "            \n",
    "            #Results the third level of the model cascade \n",
    "            #df_thres_2 dataframe contains the classified instances of model 3\n",
    "            index_selection, df_thres_3,clasif_report_M3,errors_selection_M3,score_selection_M3= classif_model(pipe3, wrist_X_selection_M2,wrist_Y_selection_M2,log_loss_T_sel,final_model=True)\n",
    "            #Classified instances\n",
    "            selection_M3=df_thres_3.shape[0]\n",
    "        else:#If number of remaining instances is not enough for 5-CV\n",
    "            #print(\"Number of pending instances not enough to perform Model3 classification\")\n",
    "            df_thres_3 = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################################################################\n",
    "        #--------------------------- FINAL MODEL---------------------------------------------------\n",
    "        ###########################################################################################\n",
    "\n",
    "        #Summary of results for the whole cascade\n",
    "        #Create dataframe containing all the classified instances\n",
    "        final= [df_thres_1, df_thres_2, df_thres_3]\n",
    "        final_df = pd.concat(final)\n",
    "        \n",
    "        #Classified instances\n",
    "        selection_M3=df_thres_3.shape[0]\n",
    "        selection_final= final_df.shape[0]\n",
    "        \n",
    "        #Errors\n",
    "        errors_selection_final= final_df[(final_df.Error_thres == 'TRUE')].shape[0]\n",
    "        \n",
    "        #Final Score\n",
    "        score_selection_final= f1_score(final_df[\"True_label\"].values, final_df[\"Pred_label\"].values, average=\"macro\")\n",
    "        score_final.append(score_selection_final)\n",
    "        original_class.extend(final_df[\"True_label\"].values)\n",
    "        predicted_class.extend(final_df[\"Pred_label\"].values)\n",
    "        \n",
    "        #Final selection adn errors\n",
    "        final_sum= selection_M1 + selection_M2 + selection_M3\n",
    "        final_sum_before_M3= selection_M1 + selection_M2\n",
    "        final_selection.append(final_sum)\n",
    "        final_selection_before_M3.append(final_sum_before_M3)\n",
    "\n",
    "    #Classification report final cascade\n",
    "    clasif_report_selection_final= classification_report(final_df[\"True_label\"].values, final_df[\"Pred_label\"].values,  digits=4) #target_names=wrist_labels_binary,\n",
    "    clasif_report_selection_final= classification_report(original_class, predicted_class, digits=4, target_names=wrist_labels)#, target_names=wrist_labels_binary\n",
    "\n",
    "\n",
    "    #------------SUMMARY MODEL 1\n",
    "    print(\" \\n Model 1 \\n\")\n",
    "    print(\" \\nInitial Mean F1_macro: \" + str(np.mean(initial_scores_M1)))\n",
    "    print(\"Mean Selection: \" + str(np.mean(selection_M1_array)) + \" - out of \" +str(len(wrist_X)))\n",
    "    print(\"Mean Number of errores selection: \" + str(np.mean(errors_selection_M1_array)))\n",
    "    print(\"Mean F1_macro selection: \"+ str(np.mean(score_selection_M1_array)))\n",
    "    print(\"Clasification report final M1 \\n\")\n",
    "    print(clasif_report_M1)\n",
    "\n",
    "    #------------SUMMARY MODEL 2\n",
    "    print(\" \\n Model 2 \\n\")\n",
    "    print(\" \\nInitial Mean F1_macro: \" + str(np.mean(initial_scores_M2)))\n",
    "    print(\"Mean Selection: \" + str(np.mean(selection_M2_array)) + \" out of \" + str (len(wrist_X) - np.mean(selection_M1_array)))\n",
    "    print(\"Mean Number of errores selection: \" + str(np.mean(errors_selection_M2_array)))\n",
    "    print(\"Mean F1_macro selection: \"+ str(np.mean(score_selection_M2_array)))\n",
    "    print(\"Mean F1_macro for M1 + M2: \"+ str(np.mean(score_final_M2)))\n",
    "    print(\"Clasification report final M2 \\n\")\n",
    "    print(clasif_report_M2)\n",
    "\n",
    "    #------------SUMMARY Final\n",
    "    print(\"\\n Final \\n\")\n",
    "    print(\"\\nFinal Mean F1_macro: \" + str(np.mean(score_final)*100)+\" - SD \" + str(np.std(score_final)*100))\n",
    "    #print('%.2f (SD %.3f)' % (np.mean(score_final)*100, np.std(score_final)*100))\n",
    "    print(\"Classified: \" + str(np.mean(final_selection)) + \" /  Not classified \" + str (len(wrist_X)- np.mean(final_selection)))\n",
    "    print(\"Classified Before Final stage: \" + str(np.mean(final_selection_before_M3)) + \"- SD \"+ str(np.std(final_selection_before_M3))+\" /  Not classified \" + \n",
    "          str (len(wrist_X)- np.mean(final_selection_before_M3)))\n",
    "    \n",
    "    print(\"Mean Number of errors selection: \" + str(np.mean(errors_selection_M1_array)+np.mean(errors_selection_M2_array)))\n",
    "    print(\"\\n Clasification report final SELECTION \\n\")\n",
    "    print(clasif_report_selection_final)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Todas classificadas Parale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________PARALEL_________\n",
      "\n",
      "--------------------------------------------------------------\n",
      "--- Number of Features Model 1: 10 Feat. - Model 2: 50 Feat. - Model 3: 486 Feat. ---\n",
      "--------------------------------------------------------------\n",
      "\n",
      "\n",
      "########### LG ##########\n",
      " \n",
      " Model 1 \n",
      "\n",
      " \n",
      "Initial Mean F1_macro: 0.666539879844612\n",
      "Mean Selection: 305.3 - out of 1000\n",
      "Mean Number of errores selection: 6.1\n",
      "Mean F1_macro selection: 0.623391531517089\n",
      "Clasification report final M1 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    0.9885    0.9942       262\n",
      "         1.0     0.0000    0.0000    0.0000         2\n",
      "         2.0     0.8000    1.0000    0.8889        20\n",
      "\n",
      "    accuracy                         0.9824       284\n",
      "   macro avg     0.6000    0.6628    0.6277       284\n",
      "weighted avg     0.9789    0.9824    0.9798       284\n",
      "\n",
      " \n",
      " Model 2 \n",
      "\n",
      " \n",
      "Initial Mean F1_macro: 0.7946448041983922\n",
      "Mean Selection: 396.8 out of 694.7\n",
      "Mean Number of errores selection: 44.6\n",
      "Mean F1_macro selection: 0.8740771884954064\n",
      "Mean F1_macro for M1 + M2: 0.8853370920845041\n",
      "Clasification report final M2 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9471    0.8995    0.9227       199\n",
      "         1.0     0.8023    0.7753    0.7886        89\n",
      "         2.0     0.8613    0.9516    0.9042       124\n",
      "\n",
      "    accuracy                         0.8883       412\n",
      "   macro avg     0.8702    0.8755    0.8718       412\n",
      "weighted avg     0.8900    0.8883    0.8882       412\n",
      "\n",
      "\n",
      " Final \n",
      "\n",
      "\n",
      "Final Mean F1_macro: 85.93776737838844 - SD 0.5987730063893959\n",
      "Classified: 1000.0 /  Not classified 0.0\n",
      "Before M3: 702.1- SD 6.7 /  Not classified 297.9\n",
      "Mean Number of errors selection: 50.7\n",
      "Clasification report final SELECTION \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other     0.9328    0.9187    0.9257      5200\n",
      " Drink_glass     0.8297    0.8000    0.8146      2400\n",
      "Drink_bottle     0.8109    0.8667    0.8379      2400\n",
      "\n",
      "    accuracy                         0.8777     10000\n",
      "   macro avg     0.8578    0.8618    0.8594     10000\n",
      "weighted avg     0.8788    0.8777    0.8779     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"________PARALEL_________\\n\")\n",
    "\n",
    "\n",
    "index_selection_M1=[]\n",
    "index_selection_M2=[]\n",
    "index_selection=[]\n",
    "wrist_X_new=[]\n",
    "wrist_Y_new=[]\n",
    "wrist_X_selection=[]\n",
    "wrist_Y_selection=[]\n",
    "wrist_X_NO_S_new=[]\n",
    "wrist_Y_NO_S_new=[]\n",
    "index_selection_M1=[]\n",
    "index_selection_M2=[]\n",
    "index_selection_M3=[]\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "original_class = []\n",
    "predicted_class = []\n",
    "selection_M1_array = [] #Selection M1\n",
    "errors_selection_M1_array = [] # Errors_selection M1\n",
    "score_selection_M1_array = [] #score selection M1\n",
    "selection_M1_array #selection\n",
    "errors_selection_M1_array #errors_selection\n",
    "score_selection_M1_array #F1 score selection\n",
    "selection_M1_array=[]\n",
    "errors_selection_M1_array=[]\n",
    "score_selection_M1_array=[]\n",
    "score_final_M2=[]\n",
    "score_final =[]\n",
    "final_selection=[]\n",
    "initial_scores_M1=[]\n",
    "initial_scores_M2=[]\n",
    "initial_scores_M3=[]\n",
    "final_selection_before_M3=[]\n",
    "scores_M3=[]\n",
    "\n",
    "labels=wrist_labels\n",
    "\n",
    "\n",
    "\n",
    "print ('--------------------------------------------------------------')\n",
    "print ('--- Number of Features Model 1: %0.0f Feat. - Model 2: %0.0f Feat. - Model 3: %0.0f Feat. ---' % (n_features_m1, n_features_m2,n_features_m3))\n",
    "print ('--------------------------------------------------------------')\n",
    "print('\\n')\n",
    "\n",
    "for item, item_name in zip(alg_array, alg_array_names): \n",
    "    print ('########### ' + str(item_name) + ' ##########')\n",
    "\n",
    "\n",
    "    for n in range(0,n_times):\n",
    "        \n",
    "        #define stratified 5-fold cross validation\n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle = True, random_state=n)\n",
    "\n",
    "\n",
    "        ###########################################################################################\n",
    "        #--------------------------- MODEL 1 ------------------------------------------------------\n",
    "        ###########################################################################################\n",
    "\n",
    "        #Feature selection definition\n",
    "        select_feature = SelectKBest(chi2, k=n_features_m1)\n",
    "        \n",
    "        #Create pipeline to perform every processing stage only for the training folds of the 5-CV\n",
    "        pipe = Pipeline([('Maxmin', preprocessing.MinMaxScaler()),\n",
    "        ('Feature selection',select_feature),\n",
    "                     ('Algorithm',item)])\n",
    "\n",
    "        \n",
    "        #Select the data input depending on segments true or false\n",
    "        X_data_M1=check_segments(segments_m1)\n",
    "\n",
    "        #Obtain reference score for model 1\n",
    "        scores_M1 = cross_val_score(pipe, X_data_M1, wrist_Y, cv =kf, scoring = 'f1_macro')\n",
    "        initial_scores_M1.append(np.mean(scores_M1))\n",
    "\n",
    "\n",
    "        #Results the fist level of the model cascade\n",
    "        #df_thres_1 dataframe contains the classified instances of model 1\n",
    "        index_selection_M1, df_thres_1,clasif_report_M1,errors_selection_M1,score_selection_M1= classif_model_paralel(pipe, X_data_M1,wrist_Y, log_loss_T,final_model=False,model_2=False)\n",
    "        \n",
    "        #Classified instances X (for segmented and no segmented data)\n",
    "        if segments_m2==True:\n",
    "            wrist_X_selection_M1=wrist_X[index_selection_M1]\n",
    "        else:\n",
    "            wrist_X_selection_M1=wrist_X_NO_S[index_selection_M1] #pending \n",
    "            wrist_X_selection_M1_segments=wrist_X[index_selection_M2]\n",
    "\n",
    "\n",
    "        #Classified instances\n",
    "        wrist_Y_selection_M1=wrist_Y[index_selection_M1] #\n",
    "        selection_M1=df_thres_1.shape[0] # Number of instances classified\n",
    "\n",
    "        #Create array for averaging results\n",
    "        initial_scores_M1.append(np.mean(scores_M1)) #Reference M1 score array\n",
    "        selection_M1_array.append(selection_M1) #Number of instances cassified M1 array\n",
    "        errors_selection_M1_array.append(errors_selection_M1) #errors selection M1 array\n",
    "        score_selection_M1_array.append(score_selection_M1) #F1 score selection M1 array\n",
    "\n",
    "\n",
    "        \n",
    "        ###########################################################################################\n",
    "        #--------------------------- MODEL 2 ------------------------------------------------------ \n",
    "        ###########################################################################################\n",
    "\n",
    "        #Feature selection definition\n",
    "        select_feature_M2 = SelectKBest(chi2, k=n_features_m2)\n",
    "        \n",
    "        #Create pipeline to perform every processing stage only for the training folds of the 5-CV\n",
    "        pipe2 = Pipeline([('Maxmin', preprocessing.MinMaxScaler()),\n",
    "            ('Feature selection',select_feature_M2), ('Algorithm',item)])\n",
    "\n",
    "        #Select the data input depending on segments true or false\n",
    "        X_data_M2=check_segments(segments_m2)\n",
    "        \n",
    "        #Obtain reference score for model 2\n",
    "        scores_M2 = cross_val_score(pipe2, X_data_M2, wrist_Y, cv =kf, scoring = 'f1_macro')\n",
    "        initial_scores_M2.append(np.mean(scores_M2))\n",
    "\n",
    "        # Check the number of remaining instances to avoid exceptions in the 5CV\n",
    "        if ((n_splits*1.5 < n_samples)and ((check_CV_instances(wrist_Y_selection_M1)== False) or (n_samples > number_classes*2))):\n",
    "            \n",
    "            #Results the second level of the model cascade \n",
    "            #df_thres_2 dataframe contains the classified instances of model 2\n",
    "            index_selection_M2, df_thres_2,clasif_report_M2,errors_selection_M2,score_selection_M2= classif_model_paralel(pipe2, X_data_M2,wrist_Y,log_loss_T_sel,final_model=False,model_2=True)\n",
    "\n",
    "            #Classified instances\n",
    "            selection_M2=df_thres_2.shape[0]\n",
    "            selection_M2_array.append(selection_M2) #Number of instances cassified\n",
    "            wrist_Y_selection=wrist_Y[index_selection_M1]\n",
    "            wrist_Y_selection_M2=wrist_Y_selection[index_selection_M2]\n",
    "            wrist_X_selection=wrist_X[index_selection_M1]\n",
    "            wrist_X_selection_M2=wrist_X_selection[index_selection_M2]\n",
    "            \n",
    "            errors_selection_M2_array.append(errors_selection_M2) #errors selection M2 array\n",
    "            score_selection_M2_array.append(score_selection_M2) #F1 score selection M2 array\n",
    "\n",
    "\n",
    "        else: #If number of remaining instances is not enough for 5-CV\n",
    "            df_thres_2 = pd.DataFrame()\n",
    "            selection_M2=0\n",
    "            index_selection_M2 =index_selection_M1\n",
    "            wrist_Y_selection_M2=wrist_Y_selection_M1\n",
    "\n",
    "            \n",
    "        #------------------ MODEL 1 + Model 2 --------------------\n",
    "        \n",
    "        #Join m1+m2 in one dataframe\n",
    "        M2_all= [df_thres_1, df_thres_2]\n",
    "        final_df_M2 = pd.concat(M2_all)\n",
    "        selection_M2_all=final_df_M2.shape[0]\n",
    "\n",
    "        #results of first two levels (m1 and m2) of the cascade\n",
    "        errors_selection_final_M2= final_df_M2[(final_df_M2.Error_thres == 'TRUE')].shape[0]\n",
    "        score_selection_final_M2= f1_score(final_df_M2[\"True_label\"].values, final_df_M2[\"Pred_label\"].values, average=\"macro\")\n",
    "        score_final_M2.append(score_selection_final_M2)\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################################################################\n",
    "        #--------------------------- MODEL 3 ------------------------------------------------------ \n",
    "        ###########################################################################################\n",
    "     \n",
    "        \n",
    "        #Feature selection definition\n",
    "        select_feature_M3 = SelectKBest(chi2, k=n_features_m3)\n",
    "        pipe3 = Pipeline([('Maxmin', preprocessing.MinMaxScaler()),\n",
    "            ('Feature selection',select_feature_M3), ('Algorithm',item)])\n",
    "        \n",
    "        #Check segments model 3\n",
    "        X_data_M3=check_segments(segments_m3)\n",
    "        \n",
    "        #Obtain reference score model 3\n",
    "        scores_M3 = cross_val_score(pipe3, wrist_X, wrist_Y, cv =kf, scoring = 'f1_macro')\n",
    "        initial_scores_M3.append(np.mean(scores_M3))\n",
    "\n",
    "\n",
    "        # Check the number of remaining instances to avoid exceptions in the 5CV\n",
    "        if ((n_splits*1.5 < n_samples)and ((check_CV_instances(wrist_Y_selection_M2)== False) or (n_samples > number_classes*2))):\n",
    "            #No treshold is applied at the last stage\n",
    "            log_loss_T_sel_3=0\n",
    "            \n",
    "            #Results the third level of the model cascade \n",
    "            #df_thres_2 dataframe contains the classified instances of model 3\n",
    "            index_selection_M3, df_thres_3,clasif_report_M3,errors_selection_M3,score_selection_M3= classif_model_paralel(pipe3, X_data_M3,wrist_Y,log_loss_T_sel,final_model=True,model_2=False)\n",
    "            #Classified instances\n",
    "            selection_M3=df_thres_3.shape[0]\n",
    "        else:#If number of remaining instances is not enough for 5-CV\n",
    "            #print(\"Number of pending instances not enough to perform Model3 classification\")\n",
    "            df_thres_3 = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################################################################\n",
    "        #--------------------------- FINAL MODEL---------------------------------------------------\n",
    "        ###########################################################################################\n",
    "\n",
    "        #Summary of results for the whole cascade\n",
    "        #Create dataframe containing all the classified instances\n",
    "        final= [df_thres_1, df_thres_2, df_thres_3]\n",
    "        final_df = pd.concat(final)\n",
    "        \n",
    "        #Classified instances\n",
    "        selection_M3=df_thres_3.shape[0]\n",
    "        selection_final= final_df.shape[0]\n",
    "        \n",
    "        #Errors\n",
    "        errors_selection_final= final_df[(final_df.Error_thres == 'TRUE')].shape[0]\n",
    "        \n",
    "        #Final Score\n",
    "        score_selection_final= f1_score(final_df[\"True_label\"].values, final_df[\"Pred_label\"].values, average=\"macro\")\n",
    "        score_final.append(score_selection_final)\n",
    "        original_class.extend(final_df[\"True_label\"].values)\n",
    "        predicted_class.extend(final_df[\"Pred_label\"].values)\n",
    "\n",
    "        #Final selection adn errors\n",
    "        final_sum= selection_M1 + selection_M2 + selection_M3\n",
    "        final_sum_before_M3= selection_M1 + selection_M2\n",
    "        final_selection.append(final_sum)\n",
    "        final_selection_before_M3.append(final_sum_before_M3)\n",
    "\n",
    "\n",
    "    #Classification report final cascade\n",
    "    clasif_report_selection_final= classification_report(final_df[\"True_label\"].values, final_df[\"Pred_label\"].values,  digits=4) #target_names=wrist_labels_binary,\n",
    "    clasif_report_selection_final= classification_report(original_class, predicted_class, digits=4, target_names=labels)#, target_names=wrist_labels_binary\n",
    "\n",
    "\n",
    "\n",
    "    print(\" \\n Model 1 \\n\")\n",
    "    print(\" \\nInitial Mean F1_macro: \" + str(np.mean(initial_scores_M1)))\n",
    "    print(\"Mean Selection: \" + str(np.mean(selection_M1_array)) + \" - out of \" +str(len(wrist_X)))\n",
    "    print(\"Mean Number of errores selection: \" + str(np.mean(errors_selection_M1_array)))\n",
    "    print(\"Mean F1_macro selection: \"+ str(np.mean(score_selection_M1_array)))\n",
    "    print(\"Clasification report final M1 \\n\")\n",
    "    print(clasif_report_M1)\n",
    "\n",
    "\n",
    "    print(\" \\n Model 2 \\n\")\n",
    "    print(\" \\nInitial Mean F1_macro: \" + str(np.mean(initial_scores_M2)))\n",
    "    print(\"Mean Selection: \" + str(np.mean(selection_M2_array)) + \" out of \" + str (len(wrist_X) - np.mean(selection_M1_array)))\n",
    "    print(\"Mean Number of errores selection: \" + str(np.mean(errors_selection_M2_array)))\n",
    "    print(\"Mean F1_macro selection: \"+ str(np.mean(score_selection_M2_array)))\n",
    "    print(\"Mean F1_macro for M1 + M2: \"+ str(np.mean(score_final_M2)))\n",
    "    print(\"Clasification report final M2 \\n\")\n",
    "    print(clasif_report_M2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n Final \\n\")\n",
    "    print(\"\\nFinal Mean F1_macro: \" + str(np.mean(score_final)*100)+\" - SD \" + str(np.std(score_final)*100))\n",
    "    #print('%.2f (SD %.3f)' % (np.mean(score_final)*100, np.std(score_final)*100))\n",
    "    print(\"Classified: \" + str(np.mean(final_selection)) + \" /  Not classified \" + str (len(wrist_X)- np.mean(final_selection)))\n",
    "    print(\"Before M3: \" + str(np.mean(final_selection_before_M3)) + \"- SD \"+ str(np.std(final_selection_before_M3))+\" /  Not classified \" + \n",
    "          str (len(wrist_X)- np.mean(final_selection_before_M3)))\n",
    "    \n",
    "    print(\"Mean Number of errors selection: \" + str(np.mean(errors_selection_M1_array)+np.mean(errors_selection_M2_array)))\n",
    "    print(\"Clasification report final SELECTION \\n\")\n",
    "    print(clasif_report_selection_final)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________HYBRID_________\n",
      "\n",
      "--------------------------------------------------------------\n",
      "--- Number of Features Model 1: 10 Feat. - Model 2: 50 Feat. - Model 3: 486 Feat. ---\n",
      "--------------------------------------------------------------\n",
      "\n",
      "\n",
      "########### LG ##########\n",
      " \n",
      " Model 1 \n",
      "\n",
      " \n",
      "Initial Mean F1_macro: 0.666539879844612\n",
      "Mean Selection: 305.3 - out of 1000\n",
      "Mean Number of errores selection: 6.1\n",
      "Mean F1_macro selection: 0.623391531517089\n",
      "Clasification report final M1 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    0.9885    0.9942       262\n",
      "         1.0     0.0000    0.0000    0.0000         2\n",
      "         2.0     0.8000    1.0000    0.8889        20\n",
      "\n",
      "    accuracy                         0.9824       284\n",
      "   macro avg     0.6000    0.6628    0.6277       284\n",
      "weighted avg     0.9789    0.9824    0.9798       284\n",
      "\n",
      " \n",
      " Model 2 \n",
      "\n",
      " \n",
      "Initial Mean F1_macro: 0.7946448041983922\n",
      "Mean Selection: 396.8 out of 694.7\n",
      "Mean Number of errores selection: 44.6\n",
      "Mean F1_macro selection: 0.8740771884954063\n",
      "Mean F1_macro for M1 + M2: 0.8853370920845041\n",
      "Clasification report final M2 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9471    0.8995    0.9227       199\n",
      "         1.0     0.8023    0.7753    0.7886        89\n",
      "         2.0     0.8613    0.9516    0.9042       124\n",
      "\n",
      "    accuracy                         0.8883       412\n",
      "   macro avg     0.8702    0.8755    0.8718       412\n",
      "weighted avg     0.8900    0.8883    0.8882       412\n",
      "\n",
      "\n",
      " Final \n",
      "\n",
      "\n",
      "Final Mean F1_macro: 86.93416906353144 - SD 0.806019412804486\n",
      "Classified: 1000.0 /  Not classified 0.0\n",
      "Before M3: 702.1- SD 6.7 /  Not classified 297.9\n",
      "Mean Number of errors selection: 50.7\n",
      "Clasification report final SELECTION \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other     0.9564    0.9075    0.9313      5200\n",
      " Drink_glass     0.8180    0.8429    0.8303      2400\n",
      "Drink_bottle     0.8149    0.8804    0.8464      2400\n",
      "\n",
      "    accuracy                         0.8855     10000\n",
      "   macro avg     0.8631    0.8769    0.8693     10000\n",
      "weighted avg     0.8892    0.8855    0.8867     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"________HYBRID_________\\n\")\n",
    "\n",
    "\n",
    "index_selection_M1=[]\n",
    "index_selection_M2=[]\n",
    "index_selection=[]\n",
    "wrist_X_new=[]\n",
    "wrist_Y_new=[]\n",
    "wrist_X_selection=[]\n",
    "wrist_Y_selection=[]\n",
    "wrist_X_NO_S_new=[]\n",
    "wrist_Y_NO_S_new=[]\n",
    "\n",
    "index_selection_M1=[]\n",
    "index_selection_M2=[]\n",
    "index_selection_M3=[]\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "original_class = []\n",
    "predicted_class = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f1_score_array_LG_pre = []\n",
    "f1_score_array_LG = []\n",
    "n_error_LG = []\n",
    "\n",
    "\n",
    "\n",
    "selection_M1_array = [] #Selection M1\n",
    "errors_selection_M1_array = [] # Errors_selection M1\n",
    "score_selection_M1_array = [] #score selection M1\n",
    "\n",
    "selection_M1_array #selection\n",
    "errors_selection_M1_array #errors_selection\n",
    "score_selection_M1_array #F1 score selection\n",
    "\n",
    "\n",
    "\n",
    "selection_M2_array= [] #Selection M2\n",
    "errors_selection_M2_array = [] # errorsSelection M2\n",
    "score_selection_M2_array= [] #score selection M2\n",
    "\n",
    "\n",
    "score_final_M2=[]\n",
    "score_final =[]\n",
    "final_selection=[]\n",
    "initial_scores_M1=[]\n",
    "initial_scores_M2=[]\n",
    "initial_scores_M3=[]\n",
    "\n",
    "threshold_mean=[]\n",
    "\n",
    "proba_NO_S=[]\n",
    "final_selection_before_M3=[]\n",
    "scores_M3=[]\n",
    "\n",
    "labels=wrist_labels\n",
    "def logloss(true_label, predicted, eps=1e-15):\n",
    "  p = np.clip(predicted, eps, 1 - eps)\n",
    "  if true_label == 1:\n",
    "    return -np.log(p)\n",
    "  else:\n",
    "    return -np.log(1 - p)\n",
    "    \n",
    "def multiclass_log_loss(y_true, y_pred,eps=1e-15):\n",
    "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "    return -(y_true * np.log(y_pred)).sum(axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print ('--------------------------------------------------------------')\n",
    "print ('--- Number of Features Model 1: %0.0f Feat. - Model 2: %0.0f Feat. - Model 3: %0.0f Feat. ---' % (n_features_m1, n_features_m2,n_features_m3))\n",
    "print ('--------------------------------------------------------------')\n",
    "print('\\n')\n",
    "\n",
    "for item, item_name in zip(alg_array, alg_array_names): \n",
    "    print ('########### ' + str(item_name) + ' ##########')\n",
    "\n",
    "\n",
    "\n",
    "    for n in range(0,n_times):\n",
    "\n",
    "        #define stratified 5-fold cross validation\n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle = True, random_state=n)\n",
    "\n",
    "        ###########################################################################################\n",
    "        #--------------------------- MODEL 1 ------------------------------------------------------\n",
    "        ###########################################################################################\n",
    "\n",
    "        #Feature selection definition\n",
    "        select_feature = SelectKBest(chi2, k=n_features_m1)\n",
    "        \n",
    "        #Create pipeline to perform every processing stage only for the training folds of the 5-CV\n",
    "        pipe = Pipeline([('Maxmin', preprocessing.MinMaxScaler()),\n",
    "        ('Feature selection',select_feature),\n",
    "                     ('Algorithm',item)])\n",
    "\n",
    "        #Select the data input depending on segments true or false\n",
    "        X_data_M1=check_segments(segments_m1)\n",
    "\n",
    "        #Obtain reference score for model 1\n",
    "        scores_M1 = cross_val_score(pipe, X_data_M1, wrist_Y, cv =kf, scoring = 'f1_macro')\n",
    "        initial_scores_M1.append(np.mean(scores_M1))\n",
    "\n",
    "\n",
    "        #Results the fist level of the model cascade\n",
    "        #df_thres_1 dataframe contains the classified instances of model 1\n",
    "        index_selection_M1, df_thres_1,clasif_report_M1,errors_selection_M1,score_selection_M1= classif_model_paralel(pipe, X_data_M1,wrist_Y, log_loss_T,final_model=False,model_2=False)\n",
    "\n",
    "        #Classified instances X (for segmented and no segmented data)\n",
    "        if segments_m2==True:\n",
    "            wrist_X_selection_M1=wrist_X[index_selection_M1]\n",
    "        else:\n",
    "            wrist_X_selection_M1=wrist_X_NO_S[index_selection_M1] #pending \n",
    "            wrist_X_selection_M1_segments=wrist_X[index_selection_M2]\n",
    "\n",
    "        #Classified instances Y\n",
    "        wrist_Y_selection_M1=wrist_Y[index_selection_M1] #pending\n",
    "        selection_M1=df_thres_1.shape[0]\n",
    "\n",
    "        #Create array for averaging results\n",
    "        initial_scores_M1.append(np.mean(scores_M1))\n",
    "        selection_M1_array.append(selection_M1) #selection\n",
    "        errors_selection_M1_array.append(errors_selection_M1) #errors_selection\n",
    "        score_selection_M1_array.append(score_selection_M1) #F1 score selection\n",
    "\n",
    "\n",
    "        ###########################################################################################\n",
    "        #--------------------------- MODEL 2 ------------------------------------------------------ \n",
    "        ###########################################################################################\n",
    "\n",
    "\n",
    "        #Feature selection definition\n",
    "        select_feature_M2 = SelectKBest(chi2, k=n_features_m2)\n",
    "                \n",
    "        #Create pipeline to perform every processing stage only for the training folds of the 5-CV\n",
    "        pipe2 = Pipeline([('Maxmin', preprocessing.MinMaxScaler()),\n",
    "            ('Feature selection',select_feature_M2), ('Algorithm',item)])\n",
    "\n",
    "        #Select the data input depending on segments true or false\n",
    "        X_data_M2=check_segments(segments_m2)\n",
    "        \n",
    "        #Obtain reference score for model 2\n",
    "        scores_M2 = cross_val_score(pipe2, X_data_M2, wrist_Y, cv =kf, scoring = 'f1_macro')\n",
    "        initial_scores_M2.append(np.mean(scores_M2))\n",
    "\n",
    "        # Check the number of remaining instances to avoid exceptions in the 5CV\n",
    "        if ((n_splits*1.5 < n_samples)and ((check_CV_instances(wrist_Y_selection_M1)== False) or (n_samples > number_classes*2))):\n",
    "            \n",
    "            #Results the second level of the model cascade \n",
    "            #df_thres_2 dataframe contains the classified instances of model 2\n",
    "            index_selection_M2, df_thres_2,clasif_report_M2,errors_selection_M2,score_selection_M2= classif_model_paralel(pipe2, X_data_M2,wrist_Y,log_loss_T_sel,final_model=False,model_2=True)\n",
    "            \n",
    "            #Classified instances\n",
    "            selection_M2=df_thres_2.shape[0]\n",
    "            selection_M2_array.append(selection_M2) #Number of instances cassified\n",
    "            errors_selection_M2_array.append(errors_selection_M2) #errors selection M2 array\n",
    "            score_selection_M2_array.append(score_selection_M2) #F1 score selection M2 array\n",
    "            \n",
    "            #Y, X selection\n",
    "            wrist_Y_selection=wrist_Y[index_selection_M1]\n",
    "            wrist_Y_selection_M2=wrist_Y_selection[index_selection_M2]\n",
    "            wrist_X_selection=wrist_X[index_selection_M1]\n",
    "            wrist_X_selection_M2=wrist_X_selection[index_selection_M2]\n",
    "            \n",
    "        else:#If number of remaining instances is not enough for 5-CV\n",
    "            df_thres_2 = pd.DataFrame()\n",
    "            selection_M2=0\n",
    "            index_selection_M2 =index_selection_M1\n",
    "            wrist_Y_selection_M2=wrist_Y_selection_M1\n",
    "            wrist_X_selection_M2=wrist_X_selection_M1\n",
    "        #------------------ MODEL 1 + Model 2 --------------------\n",
    "\n",
    "        #Join m1+m2 in one dataframe\n",
    "        M2_all= [df_thres_1, df_thres_2]\n",
    "        final_df_M2 = pd.concat(M2_all)\n",
    "        selection_M2_all=final_df_M2.shape[0]\n",
    "\n",
    "        #results of first two levels (m1 and m2) of the cascade\n",
    "        errors_selection_final_M2= final_df_M2[(final_df_M2.Error_thres == 'TRUE')].shape[0]\n",
    "        score_selection_final_M2= f1_score(final_df_M2[\"True_label\"].values, final_df_M2[\"Pred_label\"].values, average=\"macro\")\n",
    "        score_final_M2.append(score_selection_final_M2)\n",
    "\n",
    "\n",
    "\n",
    "        ###########################################################################################\n",
    "        #--------------------------- MODEL 3 ------------------------------------------------------ \n",
    "        ###########################################################################################\n",
    "\n",
    "\n",
    "        #Feature selection definition\n",
    "        select_feature_M3 = SelectKBest(chi2, k=n_features_m3)\n",
    "        pipe3 = Pipeline([('Maxmin', preprocessing.MinMaxScaler()),\n",
    "            ('Feature selection',select_feature_M3), ('Algorithm',item)])\n",
    "        \n",
    "        #Check segments model 3\n",
    "        X_data_M3=check_segments(segments_m3)\n",
    "\n",
    "        #Obtain reference score model 3\n",
    "        scores_M3 = cross_val_score(pipe3, X_data_M3, wrist_Y, cv =kf, scoring = 'f1_macro')\n",
    "        initial_scores_M3.append(np.mean(scores_M3))\n",
    "\n",
    "        \n",
    "        # Check the number of remaining instances to avoid exceptions in the 5CV\n",
    "        if ((n_splits*2 < n_samples)and ((check_CV_instances(wrist_Y_selection_M2)== False) or (n_samples > number_classes*2))):\n",
    "            #No treshold is applied at the last stage\n",
    "            log_loss_T_sel_3=0\n",
    "            #Results the third level of the model cascade \n",
    "            #df_thres_2 dataframe contains the classified instances of model 3\n",
    "            index_selection, df_thres_3,clasif_report_M3,errors_selection_M2,score_selection_M2= classif_model(pipe3, wrist_X_selection_M2,wrist_Y_selection_M2,log_loss_T_sel,final_model=True)\n",
    "            #Classified instances\n",
    "            selection_M3=df_thres_3.shape[0]\n",
    "        else:#If number of remaining instances is not enough for 5-CV\n",
    "            df_thres_3 = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "        ##########################################################################################\n",
    "        #--------------------------- FINAL MODEL---------------------------------------------------\n",
    "        ###########################################################################################\n",
    "\n",
    "\n",
    "        #Summary of results for the whole cascade\n",
    "        #Create dataframe containing all the classified instances\n",
    "        final= [df_thres_1, df_thres_2, df_thres_3]\n",
    "        final_df = pd.concat(final)\n",
    "        \n",
    "        #Classified instances\n",
    "        selection_M3=df_thres_3.shape[0]\n",
    "        selection_final= final_df.shape[0]\n",
    "        \n",
    "        #Errors\n",
    "        errors_selection_final= final_df[(final_df.Error_thres == 'TRUE')].shape[0]\n",
    "        \n",
    "        #Final Score\n",
    "        score_selection_final= f1_score(final_df[\"True_label\"].values, final_df[\"Pred_label\"].values, average=\"macro\")\n",
    "        score_final.append(score_selection_final)\n",
    "        original_class.extend(final_df[\"True_label\"].values)\n",
    "        predicted_class.extend(final_df[\"Pred_label\"].values)\n",
    "\n",
    "\n",
    "        #Final selection adn errors\n",
    "        final_sum= selection_M1 + selection_M2 + selection_M3\n",
    "        final_sum_before_M3= selection_M1 + selection_M2\n",
    "        final_selection.append(final_sum)\n",
    "        final_selection_before_M3.append(final_sum_before_M3)\n",
    "\n",
    "\n",
    "    #Classification report final cascade\n",
    "    clasif_report_selection_final= classification_report(final_df[\"True_label\"].values, final_df[\"Pred_label\"].values,  digits=4) #target_names=wrist_labels_binary,\n",
    "    clasif_report_selection_final= classification_report(original_class, predicted_class, digits=4, target_names=labels)#, target_names=wrist_labels_binary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\" \\n Model 1 \\n\")\n",
    "    print(\" \\nInitial Mean F1_macro: \" + str(np.mean(initial_scores_M1)))\n",
    "    print(\"Mean Selection: \" + str(np.mean(selection_M1_array)) + \" - out of \" +str(len(wrist_X)))\n",
    "    print(\"Mean Number of errores selection: \" + str(np.mean(errors_selection_M1_array)))\n",
    "    print(\"Mean F1_macro selection: \"+ str(np.mean(score_selection_M1_array)))\n",
    "    print(\"Clasification report final M1 \\n\")\n",
    "    print(clasif_report_M1)\n",
    "\n",
    "\n",
    "    print(\" \\n Model 2 \\n\")\n",
    "    print(\" \\nInitial Mean F1_macro: \" + str(np.mean(initial_scores_M2)))\n",
    "    print(\"Mean Selection: \" + str(np.mean(selection_M2_array)) + \" out of \" + str (len(wrist_X) - np.mean(selection_M1_array)))\n",
    "    print(\"Mean Number of errores selection: \" + str(np.mean(errors_selection_M2_array)))\n",
    "    print(\"Mean F1_macro selection: \"+ str(np.mean(score_selection_M2_array)))\n",
    "    print(\"Mean F1_macro for M1 + M2: \"+ str(np.mean(score_final_M2)))\n",
    "    print(\"Clasification report final M2 \\n\")\n",
    "    print(clasif_report_M2)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n Final \\n\")\n",
    "    print(\"\\nFinal Mean F1_macro: \" + str(np.mean(score_final)*100)+\" - SD \" + str(np.std(score_final)*100))\n",
    "    #print('%.2f (SD %.3f)' % (np.mean(score_final)*100, np.std(score_final)*100))\n",
    "    print(\"Classified: \" + str(np.mean(final_selection)) + \" /  Not classified \" + str (len(wrist_X)- np.mean(final_selection)))\n",
    "    print(\"Before M3: \" + str(np.mean(final_selection_before_M3)) + \"- SD \"+ str(np.std(final_selection_before_M3))+\" /  Not classified \" + \n",
    "          str (len(wrist_X)- np.mean(final_selection_before_M3)))\n",
    "    \n",
    "    print(\"Mean Number of errors selection: \" + str(np.mean(errors_selection_M1_array)+np.mean(errors_selection_M2_array)))\n",
    "    print(\"Clasification report final SELECTION \\n\")\n",
    "    print(clasif_report_selection_final)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
